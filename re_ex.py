# -*- coding: utf-8 -*-
"""re_ex.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oqO_G_hTQa3BtGgFyAksu37cfanHapDI
"""

import requests as www
from bs4 import BeautifulSoup
import re
from PIL import Image
import io
import urllib.request
import cv2
import numpy as np
import requests
import shutil
import matplotlib.pyplot as plt

Response = www.get('https://headlines.yahoo.co.jp/rss/zdn_n-c_sci.xml')
#print(Response.text)
#print(Response)
txt = BeautifulSoup(Response.text,'html.parser')
list=txt.findAll('item')
#print(list)
for i in range(len(list)):
  print(list[i])

target = '''<li><a href="2013062701.html"><i class="fa fa-caret-right"></i>賭けゲートボールを摘発　高齢者８人を逮捕</a></li>
<li><a href="2013062401.html"><i class="fa fa-caret-right"></i>おっとっと、イルカの製造を中止　環境団体が抗議</a></li>'''
pattern = '</i>(.+?)</a>'
L = re.findall(pattern, target)
for i in range(len(L)):
  print(L[i])

url = 'https://kyoko-np.net/national.html'
res = www.get(url)
res.encoding = res.apparent_encoding
pattern = '</i>(.+?)</a>'
L = re.findall(pattern, res.text)
for i in range(len(L)):
  print(L[i])

target2 = 'IP=133.45.131.1, IP=133.45.131.2, IP=133.45.152.2'
pattern2= '(\d{1,3}\.\d{1,3}.\d{1,3}.\d{1,3})'
L2 = re.findall(pattern2, target2)
print(L2)

target3 = '0x4500 1234 0001 1111 1100 ffff'
pattern3 = '0x(.*)'
L3 = re.search(pattern3, target3)
L3 = L3.groups()[0]
print(L3)
pattern4 = ' '
L4 = re.sub(pattern4,'',L3)
print(L4)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

def download_img(url, file_name):
    r = requests.get(url, stream=True)
    if r.status_code == 200:
        with open(file_name, 'wb') as f:
            r.raw.decode_content = True
            shutil.copyfileobj(r.raw, f)

# url = 'https://runway-webstore.com'
url = 'https://www.pokemon.co.jp'
# url = 'https://matome.naver.jp/odai/2143954199125801501'
res = www.get(url)
res.encoding = res.apparent_encoding
pattern = '''<img src="(.+?)"'''
L = re.findall(pattern, res.text)
for i in range(len(L)):
#   print(L[i])
  c=0
  for j in range(len(L[i])):
    if L[i][j] == '{' :
      c=1
  if c==1:
    continue
    
  k = len(url)
  for j in range(10,len(url)):
    if url[j] == '/' :
      if url[j+1] != '/' :
        k=j
    if k!=0:
      break
      
  if L[i][0:4] == 'http' :
    download_img(L[i], 'res' + str(i) + '.png')
    img = np.asarray(Image.open('res' + str(i) + '.png'))
    fig, axes = plt.subplots(1,1)
    axes.set_axis_off()
    axes.imshow(img)
    plt.show()
  if L[i][0:1] == '/' and L[i][0:2] != '//' and (L[i][-3:] == 'jpg' or L[i][-3:] == 'png') :
    download_img(url[0:k] + L[i], 'res' + str(i) + '.png')
    img = np.asarray(Image.open('res' + str(i) + '.png'))
    fig, axes = plt.subplots(1,1)
    axes.set_axis_off()
    axes.imshow(img)
    plt.show()
  if L[i][0:2] == '//' and (L[i][-3:] == 'jpg' or L[i][-3:] == 'png') :
    download_img("https:" + L[i], 'res' + str(i) + '.png')
    img = np.asarray(Image.open('res' + str(i) + '.png'))
    fig, axes = plt.subplots(1,1)
    axes.set_axis_off()
    axes.imshow(img)
    plt.show()